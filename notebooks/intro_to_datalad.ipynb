{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<img style=\"margin-bottom: 1em;\" src=\"../assets/datalad_logo_oneline_v1.svg\" width=\"30%\"></img>\n",
    "<h2><em>Distributed data mangement - free and open source</em></h2> \n",
    "</div>\n",
    "<br><br>\n",
    "\n",
    "# An introduction to DataLad\n",
    "\n",
    "This tutorial allows you to explore the core capabilities of the distributed data management system, DataLad, in a beginner-friendly walk-through.\n",
    "\n",
    "\n",
    "## What is *DataLad*?\n",
    "\n",
    "DataLad is a free and open-source distributed data management system that was developed to aid with everything related to the evolution of digital objects. It keeps track of your data, creates structure, ensures reproducibility, supports collaboration, and integrates with widely used data infrastructure. As explained in the [DataLad Handbook](http://handbook.datalad.org/en/latest/index.html):\n",
    "\n",
    "> *It is not only keeping track of code, it is not only keeping track of data, it is not only making sharing, retrieving and linking data (and metadata) easy, but it assists with the combination of all things necessary in the digital workflow of data and science.*\n",
    "\n",
    "DataLad can be used as a command line tool and via its Python API and is compatible with all major operating systems.\n",
    "\n",
    "### Useful *DataLad* links\n",
    "\n",
    "- [datalad.org](https://www.datalad.org/)\n",
    "- [DataLad Handbook](http://handbook.datalad.org/en/latest/index.html)\n",
    "- ['Intro to DataLad' tutorial by Adina Wagner](https://www.youtube.com/watch?v=QsAqnP7TwyY&list=PLVso6Qs8PLCiMMBXewYQjsAQLVtzAdJJX&index=4)\n",
    "\n",
    "\n",
    "## What is this notebook?\n",
    "\n",
    "By following this interactive [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/), you are guided through the step-by-step process of creating, cloning, downloading, and processing data with DataLad. It takes you through the core concepts and commands of DataLad, which include:\n",
    "\n",
    "```\n",
    "datalad create   #create your own DataLad dataset\n",
    "datalad save     #save an updated version of your DataLad dataset\n",
    "datalad clone    #install a single DataLad dataset from a remote location\n",
    "datalad get      #download a local copy of a file or files of an installed DataLad dataset\n",
    "datalad drop     #remove a local copy of a file or files of an installed DataLad dataset\n",
    "```\n",
    "\n",
    "#### Instructions:\n",
    "- All code/Markdown cells can be run using the keyboard shortcut: `Shift + Enter` or `Shift + Return`\n",
    "- It is important to run all of the cells in order from top to bottom. This is important because Jupyter Notebooks keep a global context, i.e. it remembers the results of the code that was recently executed, and takes that into account when running new code cells. For example, if you run a code cell to list the contents of a directory, then run a next cell to navigate to a different directory, then rerun the first cell, it will list the contents of the directory that you navigated to, not the one where you were originally located.\n",
    "- If you get stuck or receive errors due to running the cells in a different order, you can restart the kernel in the `Kernel` menu option above.\n",
    "\n",
    "#### Content:\n",
    "\n",
    "1. [Introduction and set-up](#1)\n",
    "2. [Version control workflows](#2)\n",
    "3. [Dataset consumption and nesting](#3)\n",
    "4. [Dataset nesting](#4)\n",
    "5. [More on data versioning, nesting, and a glimpse into reproducible paper](#5)\n",
    "6. [Reproducible analyses](#6)\n",
    "7. [Computational reproducibility](#7)\n",
    "\n",
    "\n",
    "\\**Note: this notebook is not intended to be an in-depth tutorial on the use of DataLad. For more detailed information, please refer the DataLad Handbook*\n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"1\"></div>\n",
    "\n",
    "## 1. Introduction & set-up\n",
    "\n",
    "DataLad is a command line tool and it has a Python API. Whenever I use it,\n",
    "I thus operate it in a terminal using the command line, or I use it in scripts\n",
    "such as shell scripts, Python scripts, Jupyter Notebooks, and so forth.\n",
    "In the command line, this process always starts with the general `datalad` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use its Python interface, you can import the `datalad.api as dl`.\n",
    "\n",
    "To get more information about the `datalad` command, I can type `datalad --help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalad --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find more details about how to install DataLad and its dependencies on\n",
    "all operating systems in the DataLad handbook, in the section install.\n",
    "It also details how to install DataLad on shared machines that\n",
    "you don't have administrative privileges (sudo rights) on, such as high\n",
    "performance compute clusters.\n",
    "If you already have datalad installed,\n",
    "**make sure that it is a recent version, at least 0.15 or higher**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first thing to do if you haven't done so yet is to configure your Git\n",
    "identity. Don't worry if you have never used Git. The identity you are\n",
    "configuring consists of your name and email-adress so that the changes that you\n",
    "do to a project can be associated with you as an author of the changes.\n",
    "\n",
    "Below, we demonstrate how this can be done. However, a central Git configuration has already been completed for you in this notebook, so you don't have to do this explicitly. That is why the code below is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "#git config --global --add user.name \"Adina Wagner\"\n",
    "#git config --global --add user.email \"adina.wagner@t-online.de\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset is done with the `datalad create` command. This command only needs a name, and\n",
    "it will subsequently create a new directory under this name and instruct DataLad\n",
    "to manage it. Here, the command also has an additional option, the `-c text2git`\n",
    "option. With the `-c` option, datasets can be configured in a certain way at the\n",
    "time of creation. You can find out about the details of the `text2git` configuration\n",
    "in the DataLad Handbook in sections procedures, but in general this configuration is a very useful standard configuration for datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad create -c text2git DataLad-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right after dataset creation, there is a new directory on the computer called\n",
    "`DataLad-101`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd DataLad-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls # ls does not show any output, because the dataset is empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets have the exciting features that they can record\n",
    "everything that is done inside of them, version control all content given to\n",
    "DataLad, regardless of the size this content, and have a complete history that\n",
    "you can interact with. This history is already present, although it is very\n",
    "short at this point in time. Let's check it out nevertheless.\n",
    "\n",
    "This history exists thanks to Git. Therefore, you can access the history of a\n",
    "dataset with any tool that shows you Git\n",
    "history. We'll stay basic and just use Git's built-in `git log` command, but you\n",
    "could also use tools with graphical user interfaces if you want to, for example\n",
    "tig:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"2\"></div>\n",
    "\n",
    "## 2. Version control workflows\n",
    "\n",
    "I'll start by creating a `books` directory with the `mkdir` command, and then I will download two books\n",
    "from the internet. Here, I'm using the command line tool `wget` to do this in\n",
    "order to do everything from the command line. But you can also just download the\n",
    "books manually and save them into the dataset with a file manager if you are more\n",
    "comfortable doing it this way. Remember, a dataset is just a directory on your\n",
    "computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mkdir books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget -nv https://sourceforge.net/projects/linuxcommand/files/TLCL/19.01/TLCL-19.01.pdf/download -O TLCL.pdf && wget -nv https://edisciplinas.usp.br/pluginfile.php/3252353/mod_resource/content/1/b_Swaroop_Byte_of_python.pdf -O byte-of-python.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree command can visualize the directory hierarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `datalad status` command to find out what happened in the dataset. This\n",
    "command is very helpful and reports on the current state of your dataset. Any\n",
    "content that is new or changed will be highlighted. If nothing has changed, a\n",
    "`datalad status` will report what is called a **clean dataset state**. And in\n",
    "general it is very useful to always have a clean dataset state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any content that\n",
    "we want DataLad to manage needs to be explicitly given to DataLad, it is not\n",
    "enough to simply put it inside of the dataset. To give new or changed content to\n",
    "DataLad, we need to save it using `datalad save`. This is the first time that we\n",
    "need to specify a commit message, and this is done with the `-m` option of the\n",
    "command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad save -m \"add books on Python and Unix to read later\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `git log -p -n 1` you can take a look at the most recent commit in the history,\n",
    "as well as the changes that were saved in that commit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "git log -p -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datalad save` saved all untracked contents to the dataset. Sometimes this is inconvenient. One great advantage of a datasets\n",
    "history is that it allows you to revert changes you are not happy with, but this\n",
    "is only easily possible in the units of single commits. So if one saves commits\n",
    "to several unrelated files or changes, they are hard to disentangle if you ever\n",
    "want to revert some of those changes. But if you, for example, provide a path to\n",
    "the file you want to save you can specify more precisiley what will be saved\n",
    "together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget -nv https://github.com/progit/progit2/releases/download/2.1.154/progit.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalad status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach a path to the next `datalad save` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad save -m \"add reference book about git\" books/progit.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at files that are\n",
    "frequently modified such as code or text. To try this, I will create a file\n",
    "and modify it. I do this with a [here doc](https://en.wikipedia.org/wiki/Here_document),\n",
    "but you can also write the note with an editor of your choice. If you execute this\n",
    "code snippet, make sure you copy-paste everything, starting with `cat` and ending\n",
    "with the second `EOT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cat << EOT > notes.txt\n",
    "One can create a new dataset with '\"'\"'datalad create PATH'\"'\"'.\n",
    "The dataset is created empty\n",
    "\n",
    "\n",
    "EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datalad status` will, as expected, say that there is a new untracked file in the\n",
    "dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save it with the `datalad save` command and a helpful commit message. As\n",
    "it is the only change in the dataset, there is no need to provide a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad save -m \"Add notes on datalad create\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add another note to modifiy this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cat << EOT >> notes.txt\n",
    "The command \"datalad save [-m] PATH\" saves the file\n",
    "(modifications) to history. Note to self:\n",
    "Always use informative, concise commit messages.\n",
    "\n",
    "EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `datalad status` reports the file not to be untracked, but because it\n",
    "differs now from the state it was saved under, it is reported to have been\n",
    "modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad save -m \"add note on datalad save\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at the history of this file with `git log`, the history\n",
    "neatly summarizes all of the changes that have been done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "git log -p -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"3\"></div>\n",
    "\n",
    "## 3. Dataset consumption and nesting\n",
    "\n",
    "First, create a new subdirectory to be organized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "mkdir recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, I'll install the dataset I am interested in, either from a path or\n",
    "a URL. The dataset I want to install lives on GitHub, so in order to get it, I\n",
    "will provide its URL to the `datalad clone` command. I'm also attaching to this\n",
    "call a path to where I want to have it installed. Importantly, I am installing\n",
    "this dataset as a subdataset of `DataLad-101`; in other words, I will nest the\n",
    "two datasets. This is done with the `--dataset` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad clone --dataset . https://github.com/datalad-datasets/longnow-podcasts.git recordings/longnow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are new directories in my `DataLad/101 dataset`, and in these new directories, there are\n",
    "hundreds of mp3 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "tree -d # we limit the output to directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd recordings/longnow/Long_Now__Seminars_About_Long_term_Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is the crucial and incredibly\n",
    "handy feature of DataLad datasets: at this point, after cloning, the dataset\n",
    "has small files, for example the `README`, but larger files in it don't have any\n",
    "file content yet. It only retrieved what we, in a simplified way, call **file\n",
    "availability metadata**, and shows that as the file hierarchy in the dataset. So\n",
    "while I can read the file names and find out what the dataset contains, I don't\n",
    "have the file contents yet. If I would try to play one of the recordings with the VLC player, this would fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "#vlc Long_Now__Seminars_About_Long_term_Thinking/2003_11_15__Brian_Eno__The_Long_Now.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be curious behavior, but there are many advantages to this. One is speed, and\n",
    "another one is small disk usage. Here is the total size of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du -sh  # Unix command to show size of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tiny! But we can also find out how large the dataset would be if we had all\n",
    "of its contents with `datalad status` and the `--annex` flag. In total, there are\n",
    "more than 15GB of podcasts you have now access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad status --annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get individual or groups of files,\n",
    "directories, or datasets with the datalad `get` command. This command retrieves\n",
    "the content for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad get Long_Now__Seminars_About_Long_term_Thinking/2003_11_15__Brian_Eno__The_Long_Now.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content that is already present is not re-retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad get Long_Now__Seminars_About_Long_term_Thinking/2003_11_15__Brian_Eno__The_Long_Now.mp3  \\Long_Now__Seminars_About_Long_term_Thinking/2003_12_13__Peter_Schwartz__The_Art_Of_The_Really_Long_View.mp3  \\Long_Now__Seminars_About_Long_term_Thinking/2004_01_10__George_Dyson__There_s_Plenty_of_Room_at_the_Top__Long_term_Thinking_About_Large_scale_Computing.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't need the data locally anymore, you can\n",
    "drop the content from your dataset to save diskspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad drop Long_Now__Seminars_About_Long_term_Thinking/2003_12_13__Peter_Schwartz__The_Art_Of_The_Really_Long_View.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, as long as DataLad knows where a file came from, its content can be retrieved\n",
    "again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad get Long_Now__Seminars_About_Long_term_Thinking/2003_12_13__Peter_Schwartz__The_Art_Of_The_Really_Long_View.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"4\"></div>\n",
    "\n",
    "## 4. Dataset nesting\n",
    "\n",
    "Let's take a look into the history of the `longnow` subdataset:\n",
    "we can see that it has preserved its history completely. This means that the data we\n",
    "retrieved preserved all of its provenance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "git log --reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this look in the top-level dataset? If we query `DataLad-101`'s history,\n",
    "there will be no commit about mp3 files or any of the commits we have seen in\n",
    "the subdataset. Instead, we can see that the superdataset recorded\n",
    "the `recordings/longnow` dataset as a subdataset. This means that it recorded where this dataset\n",
    "came from and what version it is in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git log -p -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subproject commit registered the most recent commit of the subdataset, and thus\n",
    "the subdataset version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd recordings/longnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"5\"></div>\n",
    "\n",
    "## 5. More on data versioning, nesting, and a glimpse into reproducible paper\n",
    "\n",
    "We'll clone a repository for a paper that shares the manuscript, the code, and the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalad clone https://github.com/psychoinformatics-de/paper-remodnav.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-level dataset has many subdatasets. One of it, `remodnav`, is a dataset that contains the source code for a Python\n",
    "package called `remodnav` used in eyetracking analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd paper-remodnav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalad subdatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cloning a dataset, its subdatasets will be known, but just as content is\n",
    "not yet retrieved for files in datasets, subdatasets of datasets are not yet\n",
    "installed. If I navigate into an uninstalled subdataset it will appear like an\n",
    "empty directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd remodnav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to install a subdataset, I use datalad `get` with the `--recursive` flag\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad get --recursive --recursion-limit 2 -n ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command doesn't only retrieve file contents, but it also installs\n",
    "subdatasets. So if you want to be really lazy, just run datalad get `--recursive -n` in the root of a dataset to install all subdatasets that are available.\n",
    "The `-n` option prevents `get` from downloading any data, so that only subdatasets\n",
    "are installed, but no data is downloaded. Here, the depth of recursion is limited.\n",
    "For one, it would take a while to install all subdatasets, but the very raw eye tracking\n",
    "dataset contains subject IDs that should not be shared, and therefore, this subdataset\n",
    "is not accessible - if you try to install all subdatasets, the source eyetracking\n",
    "data will throw an error, because it is not made publicly available.\n",
    "\n",
    "Afterwards, you can see that the `remodnav` subdataset also contains further\n",
    "subdatasets. In this case, these subdatasets contain data that is used for\n",
    "testing and validating software performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad subdatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the validation\n",
    "data subdatasets came form another lab that shared their data. After I was\n",
    "almost finished with my paper, I found another paper that reported a mistake in\n",
    "this data. The mistake was still present in the data I was using, though. So by\n",
    "inspecting the history of this dataset you can see that at one point, I\n",
    "contributed a fix that changed the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd remodnav/tests/data/anderson_etal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git log -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But because I can link subdatasets in precise version, I can\n",
    "consciously decide and openly record which version of the data I am using or\n",
    "even test how much my results change by resetting the subdataset to an ealier\n",
    "state or updating the dataset to a more recent version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"6\"></div>\n",
    "\n",
    "## 6. Reproducible analyses\n",
    "\n",
    "Not only can I version control data and consume data with datalad, I\n",
    "can also create datasets with data analyses in a way that my future self\n",
    "and others can easily and automatically recompute what was done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd ../../../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a new dataset, in this case with the `yoda` configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad create -c yoda myanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up a helpful structure for my dataset with a code directory and some `README` files,\n",
    "and applies helpful configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd myanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read up more about the YODA principles and the `yoda` configuration in the `yoda`\n",
    "section.\n",
    "\n",
    "Next, install input data as a subdataset. For this, I created a\n",
    "dataset with the `Iris` data and published it on GitHub. Here, we're installing\n",
    "it into a directory `input`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad clone -d . https://github.com/datalad-handbook/iris_data.git input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece is the code to run on the data and produce results. For this, here is a\n",
    "k-means classification analysis script written in Python. You can find this analysis\n",
    "in more detail in the `yoda_project` section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cat << EOT > code/script.py\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datalad.api as dl\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = \"input/iris.csv\"\n",
    "\n",
    "# make sure that the data are obtained (get will also install linked sub-ds!):\n",
    "dl.get(data)\n",
    "\n",
    "# prepare the data as a pandas dataframe\n",
    "df = pd.read_csv(data)\n",
    "attributes = [\"sepal_length\", \"sepal_width\", \"petal_length\",\"petal_width\", \"class\"]\n",
    "df.columns = attributes\n",
    "\n",
    "# create a pairplot to plot pairwise relationships in the dataset\n",
    "plot = sns.pairplot(df, hue='class', palette='muted')\n",
    "plot.savefig('pairwise_relationships.png')\n",
    "\n",
    "# perform a K-nearest-neighbours classification with scikit-learn\n",
    "# Step 1: split data in test and training dataset (20:80)\n",
    "array = df.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "test_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,\n",
    "                                                                    test_size=test_size,\n",
    "                                                                    random_state=seed)\n",
    "# Step 2: Fit the model and make predictions on the test dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Step 3: Save the classification report\n",
    "report = classification_report(Y_test, predictions, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose().to_csv('prediction_report.csv')\n",
    "\n",
    "EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the script is untracked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it with a `datalad save` command and also attach an identifier with\n",
    "the `--version-tag` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad save -m \"add script for kNN classification and plotting\" --version-tag ready4analysis2 code/script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge DataLad helps me to accomplish is running this script in a way\n",
    "that links the script to the results it produces and the data it was computed\n",
    "from. I can do this with the `datalad run` command. In principle, it is simple.\n",
    "You start with a clean dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, give the command you would execute to `datalad run`, in this case `python code/script.py`.\n",
    "DataLad will take the command, run it, and save all of the changes in the\n",
    "dataset that this leads to under the commit message specified with\n",
    "the `-m` option. Thus, it associates the script with the results.\n",
    "But it can be even more helpful. Here, we also specify the input data the command\n",
    "needs and DataLad will get the data beforehand. And we also specify the output\n",
    "of the command. To understand fully what this does, please read chapters\n",
    "`chapter_run` and `chapter_gitannex`, but specifying the outputs will allow me later to rerun\n",
    "the command and let me update outdated results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad run -m \"analyze iris data with classification analysis\" \\\n",
    "--input \"input/iris.csv\" \\\n",
    "--output \"prediction_report.csv\" \\\n",
    "--output \"pairwise_relationships.png\" \\\n",
    "\"python3 code/script.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLad creates a commit in my history. This commit has my commit\n",
    "message as a human readable summary of what was done, it contains the produced\n",
    "output, and it has a machine readable record that contains information on the\n",
    "input data, the results, and the command that was run to create this result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "git log -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This machine readable record is particularly helpful, because I can now instruct\n",
    "DataLad to rerun this command so that I don't have to memorize what I had done\n",
    "and people I share my dataset with don't need to ask me how this result was\n",
    "produced, but can simply let DataLad tell them.\n",
    "\n",
    "This is done with the `datalad rerun` command. For this demonstration, I have\n",
    "prepared this analysis dataset and published it to GitHub at\n",
    "[github.com/adswa/my_analysis](https://github.com/adswa/myanalysis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/adswa/myanalysis.git analysis_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd analysis_clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can clone this repository and give, for example, the checksum of the\n",
    "`datalad run` command to the `datalad rerun` command. DataLad will read the\n",
    "machine readable record of what was done and recompute the exact same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad rerun 71cb8c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows others to very easily rerun my computations, but it also spares me\n",
    "the need to remember how I executed my script, and I can ask results where they\n",
    "came from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "git log pairwise_relationships.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"7\"></div>\n",
    "\n",
    "## 7. Computational reproducibility\n",
    "\n",
    "If you don't have the required Python packages available, running the script and\n",
    "computing the results will fail. In order to be computationally reproducible,\n",
    "I need to attach the software that is necessary for a computation to this\n",
    "execution record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "cd ../myanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the way I can do this is with a DataLad extension called `datalad containers`.\n",
    "You can install this extension with pip by running\n",
    "`pip install datalad-containers`.\n",
    "This extension allows to attach software containers such as Singularity\n",
    "images to my dataset and execute my commands inside of these containers. Thus, I\n",
    "can share share data, code, code execution, and software.\n",
    "\n",
    "Here is how this works: first, I attach a software container to my dataset using\n",
    "`datalad containers-add` with a name of the container (here I call it `software`)\n",
    "and a URL or path where to find this container; here, at Singularity Hub. This\n",
    "records the software in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad containers-add software --url shub://adswa/resources:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You need to have [Singularity](https://sylabs.io/guides/3.5/user-guide/)\n",
    "installed to run this!\n",
    "\n",
    "Afterwards, rerun the analysis in the software container with the\n",
    "`datalad containers-run` command. This container works just as the `datalad run` command before, I\n",
    "only need to specify the container name. If you were to rerun such an analysis,\n",
    "DataLad would not only retrieve the input data but also the software container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "datalad containers-run -m \"rerun analysis in container\" \\\n",
    "--container-name software \\\n",
    "--input \"input/iris.csv\" \\\n",
    "--output \"prediction_report.csv\" \\\n",
    "--output \"pairwise_relationships.png\" \\\n",
    "\"python3 code/script.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about this in the section `containersrun`.\n",
    "\n",
    "**Done! Thanks for coding along!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
